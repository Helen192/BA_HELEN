{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "id": "jqULf_BbUlLa"
      },
      "outputs": [],
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "import matplotlib.pyplot as plt\n",
        "import seaborn as sns\n",
        "from sklearn.metrics import classification_report, roc_auc_score\n",
        "\n",
        "import tensorflow as tf\n",
        "from tensorflow.keras import Model, Sequential\n",
        "from tensorflow.keras.layers import Dense, Dropout"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "71lljZZrV_mS"
      },
      "source": [
        "# 1. GETTING DATA\n",
        "\n",
        "Dataset includes:\n",
        "\n",
        "* `x` : training data (all are normal samples)\n",
        "* `tx` : test data samples (some normal, some abnormal)\n",
        "* `ty` : tells you which are normal and which are not.\n",
        "  * our autoencoder would reconstruct every sample with\n",
        "ty=0 very well, and make mistakes when ty=1"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 73
        },
        "id": "O2bNgxgrUqG3",
        "outputId": "51249d2b-2232-4c32-9fb6-2b279249e48c"
      },
      "outputs": [
        {
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-9b8d6c9f-9c8e-40b4-a579-3e3416f8a19c\" name=\"files[]\" multiple disabled\n",
              "        style=\"border:none\" />\n",
              "     <output id=\"result-9b8d6c9f-9c8e-40b4-a579-3e3416f8a19c\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script>// Copyright 2017 Google LLC\n",
              "//\n",
              "// Licensed under the Apache License, Version 2.0 (the \"License\");\n",
              "// you may not use this file except in compliance with the License.\n",
              "// You may obtain a copy of the License at\n",
              "//\n",
              "//      http://www.apache.org/licenses/LICENSE-2.0\n",
              "//\n",
              "// Unless required by applicable law or agreed to in writing, software\n",
              "// distributed under the License is distributed on an \"AS IS\" BASIS,\n",
              "// WITHOUT WARRANTIES OR CONDITIONS OF ANY KIND, either express or implied.\n",
              "// See the License for the specific language governing permissions and\n",
              "// limitations under the License.\n",
              "\n",
              "/**\n",
              " * @fileoverview Helpers for google.colab Python module.\n",
              " */\n",
              "(function(scope) {\n",
              "function span(text, styleAttributes = {}) {\n",
              "  const element = document.createElement('span');\n",
              "  element.textContent = text;\n",
              "  for (const key of Object.keys(styleAttributes)) {\n",
              "    element.style[key] = styleAttributes[key];\n",
              "  }\n",
              "  return element;\n",
              "}\n",
              "\n",
              "// Max number of bytes which will be uploaded at a time.\n",
              "const MAX_PAYLOAD_SIZE = 100 * 1024;\n",
              "\n",
              "function _uploadFiles(inputId, outputId) {\n",
              "  const steps = uploadFilesStep(inputId, outputId);\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  // Cache steps on the outputElement to make it available for the next call\n",
              "  // to uploadFilesContinue from Python.\n",
              "  outputElement.steps = steps;\n",
              "\n",
              "  return _uploadFilesContinue(outputId);\n",
              "}\n",
              "\n",
              "// This is roughly an async generator (not supported in the browser yet),\n",
              "// where there are multiple asynchronous steps and the Python side is going\n",
              "// to poll for completion of each step.\n",
              "// This uses a Promise to block the python side on completion of each step,\n",
              "// then passes the result of the previous step as the input to the next step.\n",
              "function _uploadFilesContinue(outputId) {\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  const steps = outputElement.steps;\n",
              "\n",
              "  const next = steps.next(outputElement.lastPromiseValue);\n",
              "  return Promise.resolve(next.value.promise).then((value) => {\n",
              "    // Cache the last promise value to make it available to the next\n",
              "    // step of the generator.\n",
              "    outputElement.lastPromiseValue = value;\n",
              "    return next.value.response;\n",
              "  });\n",
              "}\n",
              "\n",
              "/**\n",
              " * Generator function which is called between each async step of the upload\n",
              " * process.\n",
              " * @param {string} inputId Element ID of the input file picker element.\n",
              " * @param {string} outputId Element ID of the output display.\n",
              " * @return {!Iterable<!Object>} Iterable of next steps.\n",
              " */\n",
              "function* uploadFilesStep(inputId, outputId) {\n",
              "  const inputElement = document.getElementById(inputId);\n",
              "  inputElement.disabled = false;\n",
              "\n",
              "  const outputElement = document.getElementById(outputId);\n",
              "  outputElement.innerHTML = '';\n",
              "\n",
              "  const pickedPromise = new Promise((resolve) => {\n",
              "    inputElement.addEventListener('change', (e) => {\n",
              "      resolve(e.target.files);\n",
              "    });\n",
              "  });\n",
              "\n",
              "  const cancel = document.createElement('button');\n",
              "  inputElement.parentElement.appendChild(cancel);\n",
              "  cancel.textContent = 'Cancel upload';\n",
              "  const cancelPromise = new Promise((resolve) => {\n",
              "    cancel.onclick = () => {\n",
              "      resolve(null);\n",
              "    };\n",
              "  });\n",
              "\n",
              "  // Wait for the user to pick the files.\n",
              "  const files = yield {\n",
              "    promise: Promise.race([pickedPromise, cancelPromise]),\n",
              "    response: {\n",
              "      action: 'starting',\n",
              "    }\n",
              "  };\n",
              "\n",
              "  cancel.remove();\n",
              "\n",
              "  // Disable the input element since further picks are not allowed.\n",
              "  inputElement.disabled = true;\n",
              "\n",
              "  if (!files) {\n",
              "    return {\n",
              "      response: {\n",
              "        action: 'complete',\n",
              "      }\n",
              "    };\n",
              "  }\n",
              "\n",
              "  for (const file of files) {\n",
              "    const li = document.createElement('li');\n",
              "    li.append(span(file.name, {fontWeight: 'bold'}));\n",
              "    li.append(span(\n",
              "        `(${file.type || 'n/a'}) - ${file.size} bytes, ` +\n",
              "        `last modified: ${\n",
              "            file.lastModifiedDate ? file.lastModifiedDate.toLocaleDateString() :\n",
              "                                    'n/a'} - `));\n",
              "    const percent = span('0% done');\n",
              "    li.appendChild(percent);\n",
              "\n",
              "    outputElement.appendChild(li);\n",
              "\n",
              "    const fileDataPromise = new Promise((resolve) => {\n",
              "      const reader = new FileReader();\n",
              "      reader.onload = (e) => {\n",
              "        resolve(e.target.result);\n",
              "      };\n",
              "      reader.readAsArrayBuffer(file);\n",
              "    });\n",
              "    // Wait for the data to be ready.\n",
              "    let fileData = yield {\n",
              "      promise: fileDataPromise,\n",
              "      response: {\n",
              "        action: 'continue',\n",
              "      }\n",
              "    };\n",
              "\n",
              "    // Use a chunked sending to avoid message size limits. See b/62115660.\n",
              "    let position = 0;\n",
              "    do {\n",
              "      const length = Math.min(fileData.byteLength - position, MAX_PAYLOAD_SIZE);\n",
              "      const chunk = new Uint8Array(fileData, position, length);\n",
              "      position += length;\n",
              "\n",
              "      const base64 = btoa(String.fromCharCode.apply(null, chunk));\n",
              "      yield {\n",
              "        response: {\n",
              "          action: 'append',\n",
              "          file: file.name,\n",
              "          data: base64,\n",
              "        },\n",
              "      };\n",
              "\n",
              "      let percentDone = fileData.byteLength === 0 ?\n",
              "          100 :\n",
              "          Math.round((position / fileData.byteLength) * 100);\n",
              "      percent.textContent = `${percentDone}% done`;\n",
              "\n",
              "    } while (position < fileData.byteLength);\n",
              "  }\n",
              "\n",
              "  // All done.\n",
              "  yield {\n",
              "    response: {\n",
              "      action: 'complete',\n",
              "    }\n",
              "  };\n",
              "}\n",
              "\n",
              "scope.google = scope.google || {};\n",
              "scope.google.colab = scope.google.colab || {};\n",
              "scope.google.colab._files = {\n",
              "  _uploadFiles,\n",
              "  _uploadFilesContinue,\n",
              "};\n",
              "})(self);\n",
              "</script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        },
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Saving cardio.npz to cardio.npz\n"
          ]
        }
      ],
      "source": [
        "# This code allows us to upload data from local drive\n",
        "#from google.colab import files\n",
        "#uploaded = files.upload()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "id": "smXwGjQmWJDW"
      },
      "outputs": [],
      "source": [
        "data = np.load('../data/cardio.npz')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "RM4LNk1ZWPBU"
      },
      "outputs": [],
      "source": [
        "X_train = data['x']\n",
        "X_test = data['tx']\n",
        "y_test= data['ty']"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 7,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "y4LYbRiYWRVf",
        "outputId": "e6467c49-3d92-4c27-b016-8bf94890be0e"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "array([[ 1.69798491, -0.91998844, -0.20364049, ...,  1.67981029,\n",
              "        -0.69058975, -0.49329397],\n",
              "       [ 0.85144861, -0.91998844, -0.20364049, ...,  0.57633422,\n",
              "        -0.62378908, -0.49329397],\n",
              "       [-2.11142843, -0.18061463, -0.20364049, ..., -1.56165067,\n",
              "        -0.59038875, -2.12660547],\n",
              "       ...,\n",
              "       [ 1.27471676, -0.91998844, -0.20364049, ...,  0.85220324,\n",
              "        -0.62378908,  1.14001753],\n",
              "       [ 1.27471676,  1.71403076, -0.04677629, ...,  1.26600677,\n",
              "        -0.49018775,  1.14001753],\n",
              "       [ 0.5339975 ,  1.17365699, -0.18424532, ...,  0.99013775,\n",
              "         1.1464286 ,  1.14001753]])"
            ]
          },
          "execution_count": 7,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 72,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "09xLt-WSWULm",
        "outputId": "4957d7c6-19ab-407b-bed4-5536c41198f9"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(1479, 21)"
            ]
          },
          "execution_count": 72,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 74,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YGJmgQlgWW6I",
        "outputId": "09aab1b5-88fd-4e6a-f768-f1d04bc8f7ad"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "(352, 21)"
            ]
          },
          "execution_count": 74,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_test.shape"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 75,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "abTO_GEiWaUq",
        "outputId": "74151911-d8ff-493d-a15b-255350eaf677"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "-3.0048923462960526"
            ]
          },
          "execution_count": 75,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.min()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 76,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_KFstw56WgGm",
        "outputId": "dc7d7158-f17b-4d18-d561-0793259bfb80"
      },
      "outputs": [
        {
          "data": {
            "text/plain": [
              "14.025335380634532"
            ]
          },
          "execution_count": 76,
          "metadata": {},
          "output_type": "execute_result"
        }
      ],
      "source": [
        "X_train.max()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "sCcI6XdKWo9z"
      },
      "source": [
        "# 2. Feature scaling\n",
        "- Using MinMaxScaler() in Scikit-learn to scale data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 77,
      "metadata": {
        "id": "z-7vjDX-XLjp"
      },
      "outputs": [],
      "source": [
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler(feature_range=(0, 1))\n",
        "X_train_scaled = scaler.fit_transform(X_train.copy())\n",
        "X_test_scaled = scaler.transform(X_test.copy())"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "pGDJYFHpYKr6"
      },
      "source": [
        "# 3. Create Autoencoder Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 78,
      "metadata": {
        "id": "VSpHn1aEbU6R"
      },
      "outputs": [],
      "source": [
        "# Create a model by subclassing Model class in tensorflow\n",
        "class Autoencoder(Model):\n",
        "  \"\"\"\n",
        "  An autoencoder with Encoder and decoder blocks\n",
        "  \n",
        "  Arguments:\n",
        "    input_dim -- number of NN units at layer 0 (input)\n",
        "         \n",
        "  Returns: \n",
        "    autoencoder -- autoencoder Model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "    # encoder block\n",
        "    self.encoder = Sequential([\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(8, activation='relu')\n",
        "    ])\n",
        "    # Decoder block\n",
        "    self.decoder = Sequential([\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(64, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(input_dim, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    encode = self.encoder(inputs)\n",
        "    decode = self.decoder(encode)\n",
        "    return decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 79,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "VknRpTkDWiKL",
        "outputId": "1337b5ca-d01e-4d54-fad9-d605a35eafb1"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/100\n",
            "6/6 [==============================] - 1s 38ms/step - loss: 0.0702 - mse: 0.1151 - val_loss: 0.0765 - val_mse: 0.1293\n",
            "Epoch 2/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0654 - mse: 0.1063 - val_loss: 0.0703 - val_mse: 0.1184\n",
            "Epoch 3/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0570 - mse: 0.0915 - val_loss: 0.0599 - val_mse: 0.1014\n",
            "Epoch 4/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0447 - mse: 0.0715 - val_loss: 0.0473 - val_mse: 0.0834\n",
            "Epoch 5/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0327 - mse: 0.0537 - val_loss: 0.0394 - val_mse: 0.0751\n",
            "Epoch 6/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0265 - mse: 0.0459 - val_loss: 0.0376 - val_mse: 0.0737\n",
            "Epoch 7/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0237 - mse: 0.0421 - val_loss: 0.0361 - val_mse: 0.0707\n",
            "Epoch 8/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0216 - mse: 0.0386 - val_loss: 0.0346 - val_mse: 0.0674\n",
            "Epoch 9/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0202 - mse: 0.0363 - val_loss: 0.0337 - val_mse: 0.0656\n",
            "Epoch 10/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0196 - mse: 0.0352 - val_loss: 0.0332 - val_mse: 0.0649\n",
            "Epoch 11/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0188 - mse: 0.0341 - val_loss: 0.0330 - val_mse: 0.0649\n",
            "Epoch 12/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0186 - mse: 0.0339 - val_loss: 0.0329 - val_mse: 0.0648\n",
            "Epoch 13/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0181 - mse: 0.0331 - val_loss: 0.0328 - val_mse: 0.0646\n",
            "Epoch 14/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0177 - mse: 0.0324 - val_loss: 0.0323 - val_mse: 0.0638\n",
            "Epoch 15/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0175 - mse: 0.0321 - val_loss: 0.0320 - val_mse: 0.0632\n",
            "Epoch 16/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0174 - mse: 0.0319 - val_loss: 0.0318 - val_mse: 0.0628\n",
            "Epoch 17/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0171 - mse: 0.0313 - val_loss: 0.0316 - val_mse: 0.0624\n",
            "Epoch 18/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0169 - mse: 0.0311 - val_loss: 0.0313 - val_mse: 0.0618\n",
            "Epoch 19/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0166 - mse: 0.0307 - val_loss: 0.0311 - val_mse: 0.0615\n",
            "Epoch 20/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0164 - mse: 0.0303 - val_loss: 0.0310 - val_mse: 0.0612\n",
            "Epoch 21/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0162 - mse: 0.0299 - val_loss: 0.0306 - val_mse: 0.0606\n",
            "Epoch 22/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0160 - mse: 0.0296 - val_loss: 0.0304 - val_mse: 0.0602\n",
            "Epoch 23/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0157 - mse: 0.0291 - val_loss: 0.0301 - val_mse: 0.0597\n",
            "Epoch 24/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0157 - mse: 0.0291 - val_loss: 0.0300 - val_mse: 0.0594\n",
            "Epoch 25/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0155 - mse: 0.0287 - val_loss: 0.0297 - val_mse: 0.0590\n",
            "Epoch 26/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0153 - mse: 0.0284 - val_loss: 0.0294 - val_mse: 0.0584\n",
            "Epoch 27/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0150 - mse: 0.0279 - val_loss: 0.0290 - val_mse: 0.0577\n",
            "Epoch 28/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0148 - mse: 0.0276 - val_loss: 0.0285 - val_mse: 0.0569\n",
            "Epoch 29/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0145 - mse: 0.0271 - val_loss: 0.0281 - val_mse: 0.0559\n",
            "Epoch 30/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0141 - mse: 0.0263 - val_loss: 0.0275 - val_mse: 0.0550\n",
            "Epoch 31/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0138 - mse: 0.0257 - val_loss: 0.0271 - val_mse: 0.0542\n",
            "Epoch 32/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0135 - mse: 0.0251 - val_loss: 0.0266 - val_mse: 0.0533\n",
            "Epoch 33/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0130 - mse: 0.0243 - val_loss: 0.0264 - val_mse: 0.0530\n",
            "Epoch 34/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0127 - mse: 0.0238 - val_loss: 0.0262 - val_mse: 0.0527\n",
            "Epoch 35/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0127 - mse: 0.0237 - val_loss: 0.0261 - val_mse: 0.0525\n",
            "Epoch 36/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0123 - mse: 0.0230 - val_loss: 0.0260 - val_mse: 0.0523\n",
            "Epoch 37/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0122 - mse: 0.0229 - val_loss: 0.0260 - val_mse: 0.0524\n",
            "Epoch 38/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0121 - mse: 0.0227 - val_loss: 0.0260 - val_mse: 0.0525\n",
            "Epoch 39/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0120 - mse: 0.0224 - val_loss: 0.0259 - val_mse: 0.0522\n",
            "Epoch 40/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0120 - mse: 0.0224 - val_loss: 0.0257 - val_mse: 0.0519\n",
            "Epoch 41/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0118 - mse: 0.0220 - val_loss: 0.0256 - val_mse: 0.0517\n",
            "Epoch 42/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0117 - mse: 0.0219 - val_loss: 0.0255 - val_mse: 0.0517\n",
            "Epoch 43/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0117 - mse: 0.0218 - val_loss: 0.0254 - val_mse: 0.0515\n",
            "Epoch 44/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0116 - mse: 0.0217 - val_loss: 0.0253 - val_mse: 0.0513\n",
            "Epoch 45/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0115 - mse: 0.0216 - val_loss: 0.0253 - val_mse: 0.0512\n",
            "Epoch 46/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0114 - mse: 0.0214 - val_loss: 0.0251 - val_mse: 0.0508\n",
            "Epoch 47/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0113 - mse: 0.0212 - val_loss: 0.0250 - val_mse: 0.0506\n",
            "Epoch 48/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0112 - mse: 0.0210 - val_loss: 0.0248 - val_mse: 0.0503\n",
            "Epoch 49/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0111 - mse: 0.0208 - val_loss: 0.0248 - val_mse: 0.0503\n",
            "Epoch 50/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0110 - mse: 0.0206 - val_loss: 0.0246 - val_mse: 0.0500\n",
            "Epoch 51/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0109 - mse: 0.0205 - val_loss: 0.0245 - val_mse: 0.0498\n",
            "Epoch 52/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0108 - mse: 0.0203 - val_loss: 0.0244 - val_mse: 0.0496\n",
            "Epoch 53/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0107 - mse: 0.0201 - val_loss: 0.0241 - val_mse: 0.0491\n",
            "Epoch 54/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0106 - mse: 0.0199 - val_loss: 0.0239 - val_mse: 0.0487\n",
            "Epoch 55/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0104 - mse: 0.0195 - val_loss: 0.0237 - val_mse: 0.0483\n",
            "Epoch 56/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0104 - mse: 0.0194 - val_loss: 0.0235 - val_mse: 0.0478\n",
            "Epoch 57/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0102 - mse: 0.0191 - val_loss: 0.0231 - val_mse: 0.0472\n",
            "Epoch 58/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0101 - mse: 0.0189 - val_loss: 0.0228 - val_mse: 0.0466\n",
            "Epoch 59/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0098 - mse: 0.0183 - val_loss: 0.0225 - val_mse: 0.0460\n",
            "Epoch 60/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0097 - mse: 0.0181 - val_loss: 0.0221 - val_mse: 0.0452\n",
            "Epoch 61/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0095 - mse: 0.0177 - val_loss: 0.0219 - val_mse: 0.0448\n",
            "Epoch 62/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0094 - mse: 0.0175 - val_loss: 0.0216 - val_mse: 0.0442\n",
            "Epoch 63/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0092 - mse: 0.0170 - val_loss: 0.0214 - val_mse: 0.0439\n",
            "Epoch 64/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0092 - mse: 0.0172 - val_loss: 0.0212 - val_mse: 0.0434\n",
            "Epoch 65/100\n",
            "6/6 [==============================] - 0s 14ms/step - loss: 0.0090 - mse: 0.0166 - val_loss: 0.0210 - val_mse: 0.0432\n",
            "Epoch 66/100\n",
            "6/6 [==============================] - 0s 16ms/step - loss: 0.0090 - mse: 0.0167 - val_loss: 0.0209 - val_mse: 0.0430\n",
            "Epoch 67/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0088 - mse: 0.0163 - val_loss: 0.0207 - val_mse: 0.0426\n",
            "Epoch 68/100\n",
            "6/6 [==============================] - 0s 15ms/step - loss: 0.0087 - mse: 0.0162 - val_loss: 0.0206 - val_mse: 0.0424\n",
            "Epoch 69/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0089 - mse: 0.0164 - val_loss: 0.0204 - val_mse: 0.0420\n",
            "Epoch 70/100\n",
            "6/6 [==============================] - 0s 13ms/step - loss: 0.0086 - mse: 0.0160 - val_loss: 0.0203 - val_mse: 0.0419\n",
            "Epoch 71/100\n",
            "6/6 [==============================] - 0s 10ms/step - loss: 0.0086 - mse: 0.0159 - val_loss: 0.0201 - val_mse: 0.0416\n",
            "Epoch 72/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0086 - mse: 0.0158 - val_loss: 0.0200 - val_mse: 0.0414\n",
            "Epoch 73/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0084 - mse: 0.0156 - val_loss: 0.0199 - val_mse: 0.0412\n",
            "Epoch 74/100\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0084 - mse: 0.0155 - val_loss: 0.0198 - val_mse: 0.0410\n",
            "Epoch 75/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0084 - mse: 0.0155 - val_loss: 0.0196 - val_mse: 0.0407\n",
            "Epoch 76/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0084 - mse: 0.0156 - val_loss: 0.0195 - val_mse: 0.0404\n",
            "Epoch 77/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0083 - mse: 0.0153 - val_loss: 0.0193 - val_mse: 0.0402\n",
            "Epoch 78/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0082 - mse: 0.0151 - val_loss: 0.0192 - val_mse: 0.0399\n",
            "Epoch 79/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0082 - mse: 0.0151 - val_loss: 0.0191 - val_mse: 0.0396\n",
            "Epoch 80/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0082 - mse: 0.0151 - val_loss: 0.0189 - val_mse: 0.0394\n",
            "Epoch 81/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0079 - mse: 0.0146 - val_loss: 0.0189 - val_mse: 0.0394\n",
            "Epoch 82/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0081 - mse: 0.0149 - val_loss: 0.0188 - val_mse: 0.0392\n",
            "Epoch 83/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0081 - mse: 0.0150 - val_loss: 0.0187 - val_mse: 0.0390\n",
            "Epoch 84/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0080 - mse: 0.0147 - val_loss: 0.0187 - val_mse: 0.0389\n",
            "Epoch 85/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0078 - mse: 0.0145 - val_loss: 0.0186 - val_mse: 0.0388\n",
            "Epoch 86/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0079 - mse: 0.0146 - val_loss: 0.0184 - val_mse: 0.0385\n",
            "Epoch 87/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0144 - val_loss: 0.0182 - val_mse: 0.0382\n",
            "Epoch 88/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0145 - val_loss: 0.0181 - val_mse: 0.0379\n",
            "Epoch 89/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0144 - val_loss: 0.0182 - val_mse: 0.0381\n",
            "Epoch 90/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0077 - mse: 0.0143 - val_loss: 0.0179 - val_mse: 0.0377\n",
            "Epoch 91/100\n",
            "6/6 [==============================] - 0s 11ms/step - loss: 0.0077 - mse: 0.0143 - val_loss: 0.0178 - val_mse: 0.0373\n",
            "Epoch 92/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0078 - mse: 0.0145 - val_loss: 0.0177 - val_mse: 0.0372\n",
            "Epoch 93/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0077 - mse: 0.0143 - val_loss: 0.0176 - val_mse: 0.0370\n",
            "Epoch 94/100\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0077 - mse: 0.0142 - val_loss: 0.0176 - val_mse: 0.0370\n",
            "Epoch 95/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0077 - mse: 0.0142 - val_loss: 0.0175 - val_mse: 0.0367\n",
            "Epoch 96/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0076 - mse: 0.0140 - val_loss: 0.0174 - val_mse: 0.0366\n",
            "Epoch 97/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0076 - mse: 0.0140 - val_loss: 0.0173 - val_mse: 0.0364\n",
            "Epoch 98/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0075 - mse: 0.0137 - val_loss: 0.0172 - val_mse: 0.0363\n",
            "Epoch 99/100\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0075 - mse: 0.0138 - val_loss: 0.0172 - val_mse: 0.0362\n",
            "Epoch 100/100\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0075 - mse: 0.0139 - val_loss: 0.0169 - val_mse: 0.0356\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "autoencoder = Autoencoder(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "autoencoder.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 100\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Fit the autoencoder\n",
        "history = autoencoder.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 80,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 472
        },
        "id": "VWYi-cCNXs1U",
        "outputId": "78208f51-1bcf-44c6-8fad-9f5e2a292482"
      },
      "outputs": [
        {
          "data": {
            "image/png": "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",
            "text/plain": [
              "<Figure size 640x480 with 1 Axes>"
            ]
          },
          "metadata": {},
          "output_type": "display_data"
        }
      ],
      "source": [
        "# Plot the training and validation accuracy and loss at each epoch\n",
        "loss = history.history['loss']\n",
        "val_loss = history.history['val_loss']\n",
        "epochs = range(1, len(loss) + 1)\n",
        "plt.plot(epochs, loss, 'g', label='Training loss')\n",
        "plt.plot(epochs, val_loss, 'r', label='Validation loss')\n",
        "plt.title('Training and validation loss')\n",
        "plt.xlabel('Epochs')\n",
        "plt.ylabel('Loss')\n",
        "plt.legend()\n",
        "plt.show()"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "QYrDAWMiiHF-"
      },
      "source": [
        "# 4. Finding a threshold\n",
        "\n",
        "Figuring out a threshold which will be used to determine whether a prediction is normal or abnormal\n",
        "\n",
        "?? Finding more methods to determine a threshold"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 81,
      "metadata": {
        "id": "EF584TWSh4WP"
      },
      "outputs": [],
      "source": [
        "def get_threshold(model, X_train):\n",
        "  \"\"\"\n",
        "  Determine a threshold for anomalies\n",
        "  \n",
        "  Arguments:\n",
        "    model -- trained model\n",
        "    X_train -- input data which was used to train the model\n",
        "         \n",
        "  Returns: \n",
        "    threshold -- any prediction value bigger than threshold is anomalies\n",
        "  \"\"\"\n",
        "  # getting predictions (recontructions) of the input data\n",
        "  preds = model.predict(X_train)\n",
        "  # calculate the difference between predictions and input data\n",
        "  pred_errors = tf.keras.losses.msle(preds, X_train)\n",
        "  # Calculate threshold for anomalies\n",
        "  threshold = np.mean(pred_errors.numpy()) + np.std(pred_errors.numpy()) \n",
        "  return threshold\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "KriXv_ZenGOv"
      },
      "source": [
        "# 5. Classifying predictions into classes:\n",
        "\n",
        "* 0: normal sample\n",
        "* 1: anomaly\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 82,
      "metadata": {
        "id": "29p-8jD3h4nF"
      },
      "outputs": [],
      "source": [
        "def get_predictions(model, X_test, threshold):\n",
        "  \"\"\"\n",
        "  Get all predictions of samples\n",
        "  \n",
        "  Arguments:\n",
        "    model -- trained model\n",
        "    X_test -- samples, which should be predicted by the trained model\n",
        "    threshold -- value to determine a prediction is anomaly or not\n",
        "         \n",
        "  Returns: \n",
        "    y_preds -- predicted labels of each sample (0: normal, 1: abnormal)\n",
        "  \"\"\"\n",
        "  pred = model.predict(X_test)\n",
        "  pred_errors = tf.keras.losses.msle(pred, X_test)\n",
        "  y_preds = [0 if i < threshold else 1 for i in pred_errors]\n",
        "  return y_preds\n",
        "\n"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Z9TlD8cmqZal"
      },
      "source": [
        "# 6. Autoencoder Anomaly Detection Performance"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 83,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H4XqIUXyqcRF",
        "outputId": "f0036695-4d81-4062-c610-20272c2948dd"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 914us/step\n",
            "Thrshold: 0.009893303120785669\n",
            "11/11 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.85      0.85      0.85       176\n",
            "           1       0.85      0.85      0.85       176\n",
            "\n",
            "    accuracy                           0.85       352\n",
            "   macro avg       0.85      0.85      0.85       352\n",
            "weighted avg       0.85      0.85      0.85       352\n",
            "\n",
            "AUC: 0.8494318181818182\n"
          ]
        }
      ],
      "source": [
        "threshold = get_threshold(autoencoder, X_train_scaled)\n",
        "print(f\"Thrshold: {threshold}\")\n",
        "\n",
        "# get predictions of X_test_scaled\n",
        "y_preds = get_predictions(autoencoder, X_test_scaled, threshold)\n",
        "\n",
        "# Check the prediction performance\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(y_test, y_preds))\n",
        "\n",
        "from sklearn.metrics import roc_auc_score\n",
        "auc_score = roc_auc_score(y_test, y_preds)\n",
        "print(f\"AUC: {auc_score}\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 84,
      "metadata": {
        "id": "o3evBjgiuAJi"
      },
      "outputs": [],
      "source": [
        "# the above code block can be write in a function\n",
        "def performance(model, X_train, X_test):\n",
        "  threshold = get_threshold(model, X_train)\n",
        "  print(f\"Threshold: {threshold}\")\n",
        "\n",
        "  # get predictions of X_test_scaled\n",
        "  y_preds = get_predictions(model, X_test, threshold)\n",
        "\n",
        "  # Check the prediction performance\n",
        "  print(classification_report(y_test, y_preds))\n",
        "  auc_score = roc_auc_score(y_test, y_preds)\n",
        "  print(f\"AUC: {auc_score}\")"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "Dl5qPBohso67"
      },
      "source": [
        "# 7. Tuning hyperparameters to get better models"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 85,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "H2jNmc4JsxwX",
        "outputId": "17622557-9ce4-4b27-f5e7-58dcccec3d1f"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 2s 22ms/step - loss: 0.0705 - mse: 0.1157 - val_loss: 0.0755 - val_mse: 0.1276\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0614 - mse: 0.0992 - val_loss: 0.0595 - val_mse: 0.1015\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0402 - mse: 0.0651 - val_loss: 0.0414 - val_mse: 0.0792\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 9ms/step - loss: 0.0258 - mse: 0.0449 - val_loss: 0.0362 - val_mse: 0.0698\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0217 - mse: 0.0385 - val_loss: 0.0348 - val_mse: 0.0677\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0193 - mse: 0.0348 - val_loss: 0.0327 - val_mse: 0.0648\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0181 - mse: 0.0331 - val_loss: 0.0319 - val_mse: 0.0631\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0173 - mse: 0.0317 - val_loss: 0.0313 - val_mse: 0.0620\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0169 - mse: 0.0311 - val_loss: 0.0304 - val_mse: 0.0606\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0162 - mse: 0.0300 - val_loss: 0.0295 - val_mse: 0.0589\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0156 - mse: 0.0289 - val_loss: 0.0286 - val_mse: 0.0574\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0148 - mse: 0.0275 - val_loss: 0.0278 - val_mse: 0.0560\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0142 - mse: 0.0265 - val_loss: 0.0271 - val_mse: 0.0546\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0136 - mse: 0.0252 - val_loss: 0.0268 - val_mse: 0.0540\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0132 - mse: 0.0245 - val_loss: 0.0265 - val_mse: 0.0535\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0128 - mse: 0.0238 - val_loss: 0.0261 - val_mse: 0.0529\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 0.0234 - val_loss: 0.0262 - val_mse: 0.0530\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0229 - val_loss: 0.0260 - val_mse: 0.0526\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0121 - mse: 0.0225 - val_loss: 0.0258 - val_mse: 0.0520\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0119 - mse: 0.0221 - val_loss: 0.0256 - val_mse: 0.0516\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "autoencoder_2 = Autoencoder(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "autoencoder_2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_2 = autoencoder_2.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 86,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "R_BNsVWTs93f",
        "outputId": "a52383a3-8019-4121-a198-0b4635e9229b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 879us/step\n",
            "Threshold: 0.016654403516558874\n",
            "11/11 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88       176\n",
            "           1       0.84      0.94      0.89       176\n",
            "\n",
            "    accuracy                           0.88       352\n",
            "   macro avg       0.89      0.88      0.88       352\n",
            "weighted avg       0.89      0.88      0.88       352\n",
            "\n",
            "AUC: 0.8835227272727273\n"
          ]
        }
      ],
      "source": [
        "performance(autoencoder_2, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 87,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "3zT0MWTNvFQ4",
        "outputId": "ed871751-2b5e-410a-e244-11cc5d443d73"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/10\n",
            "6/6 [==============================] - 1s 38ms/step - loss: 0.0729 - mse: 0.1201 - val_loss: 0.0793 - val_mse: 0.1345\n",
            "Epoch 2/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0705 - mse: 0.1156 - val_loss: 0.0781 - val_mse: 0.1323\n",
            "Epoch 3/10\n",
            "6/6 [==============================] - 0s 12ms/step - loss: 0.0690 - mse: 0.1127 - val_loss: 0.0764 - val_mse: 0.1292\n",
            "Epoch 4/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0666 - mse: 0.1082 - val_loss: 0.0734 - val_mse: 0.1238\n",
            "Epoch 5/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0622 - mse: 0.1002 - val_loss: 0.0678 - val_mse: 0.1142\n",
            "Epoch 6/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0544 - mse: 0.0865 - val_loss: 0.0583 - val_mse: 0.0990\n",
            "Epoch 7/10\n",
            "6/6 [==============================] - 0s 7ms/step - loss: 0.0421 - mse: 0.0669 - val_loss: 0.0459 - val_mse: 0.0818\n",
            "Epoch 8/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0306 - mse: 0.0503 - val_loss: 0.0390 - val_mse: 0.0756\n",
            "Epoch 9/10\n",
            "6/6 [==============================] - 0s 9ms/step - loss: 0.0255 - mse: 0.0445 - val_loss: 0.0382 - val_mse: 0.0760\n",
            "Epoch 10/10\n",
            "6/6 [==============================] - 0s 8ms/step - loss: 0.0232 - mse: 0.0414 - val_loss: 0.0357 - val_mse: 0.0710\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "autoencoder_3 = Autoencoder(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "autoencoder_3.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 10\n",
        "BATCH_SIZE = 256\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_3 = autoencoder_3.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 88,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "s92liMjAwCIj",
        "outputId": "790c3b25-0239-4df7-9ed0-5adaaf1cd320"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 2ms/step\n",
            "Threshold: 0.029546466532260597\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.89      0.84      0.86       176\n",
            "           1       0.84      0.89      0.87       176\n",
            "\n",
            "    accuracy                           0.86       352\n",
            "   macro avg       0.86      0.86      0.86       352\n",
            "weighted avg       0.86      0.86      0.86       352\n",
            "\n",
            "AUC: 0.8636363636363636\n"
          ]
        }
      ],
      "source": [
        "performance(autoencoder_3, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 91,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "EIdc06tRwDL7",
        "outputId": "0f6485df-b775-4b76-ebe2-0c43eaed0e00"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "24/24 [==============================] - 2s 9ms/step - loss: 0.0695 - mse: 0.1136 - val_loss: 0.0720 - val_mse: 0.1214\n",
            "Epoch 2/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0438 - mse: 0.0710 - val_loss: 0.0393 - val_mse: 0.0754\n",
            "Epoch 3/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0216 - mse: 0.0383 - val_loss: 0.0340 - val_mse: 0.0663\n",
            "Epoch 4/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0328 - val_loss: 0.0327 - val_mse: 0.0646\n",
            "Epoch 5/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0171 - mse: 0.0315 - val_loss: 0.0316 - val_mse: 0.0623\n",
            "Epoch 6/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0161 - mse: 0.0299 - val_loss: 0.0308 - val_mse: 0.0612\n",
            "Epoch 7/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0157 - mse: 0.0292 - val_loss: 0.0305 - val_mse: 0.0607\n",
            "Epoch 8/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0153 - mse: 0.0285 - val_loss: 0.0298 - val_mse: 0.0595\n",
            "Epoch 9/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0146 - mse: 0.0273 - val_loss: 0.0289 - val_mse: 0.0580\n",
            "Epoch 10/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0140 - mse: 0.0264 - val_loss: 0.0274 - val_mse: 0.0551\n",
            "Epoch 11/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0246 - val_loss: 0.0266 - val_mse: 0.0537\n",
            "Epoch 12/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0123 - mse: 0.0231 - val_loss: 0.0262 - val_mse: 0.0530\n",
            "Epoch 13/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0120 - mse: 0.0224 - val_loss: 0.0262 - val_mse: 0.0531\n",
            "Epoch 14/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0119 - mse: 0.0223 - val_loss: 0.0257 - val_mse: 0.0522\n",
            "Epoch 15/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0116 - mse: 0.0217 - val_loss: 0.0258 - val_mse: 0.0522\n",
            "Epoch 16/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0114 - mse: 0.0213 - val_loss: 0.0254 - val_mse: 0.0515\n",
            "Epoch 17/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0113 - mse: 0.0212 - val_loss: 0.0253 - val_mse: 0.0514\n",
            "Epoch 18/20\n",
            "24/24 [==============================] - 0s 3ms/step - loss: 0.0111 - mse: 0.0208 - val_loss: 0.0248 - val_mse: 0.0504\n",
            "Epoch 19/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0108 - mse: 0.0203 - val_loss: 0.0241 - val_mse: 0.0490\n",
            "Epoch 20/20\n",
            "24/24 [==============================] - 0s 4ms/step - loss: 0.0106 - mse: 0.0198 - val_loss: 0.0234 - val_mse: 0.0475\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "autoencoder_4 = Autoencoder(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "autoencoder_4.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 64\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_4 = autoencoder_4.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 92,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TIpQhLcOwUGA",
        "outputId": "b77b1ae3-e2bb-4479-a880-9a8bb445140d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 862us/step\n",
            "Threshold: 0.015113364702069584\n",
            "11/11 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.90      0.85      0.88       176\n",
            "           1       0.86      0.91      0.88       176\n",
            "\n",
            "    accuracy                           0.88       352\n",
            "   macro avg       0.88      0.88      0.88       352\n",
            "weighted avg       0.88      0.88      0.88       352\n",
            "\n",
            "AUC: 0.8806818181818182\n"
          ]
        }
      ],
      "source": [
        "performance(autoencoder_4, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 93,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_wE1IUdMwY_I",
        "outputId": "a6c075ce-1f94-48ef-b9fc-89a0efb4f5a2"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 18ms/step - loss: 0.0709 - mse: 0.1164 - val_loss: 0.0777 - val_mse: 0.1318\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0651 - mse: 0.1059 - val_loss: 0.0682 - val_mse: 0.1159\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0475 - mse: 0.0770 - val_loss: 0.0493 - val_mse: 0.0900\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0304 - mse: 0.0517 - val_loss: 0.0371 - val_mse: 0.0713\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0228 - mse: 0.0404 - val_loss: 0.0338 - val_mse: 0.0654\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0199 - mse: 0.0355 - val_loss: 0.0337 - val_mse: 0.0658\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0188 - mse: 0.0340 - val_loss: 0.0328 - val_mse: 0.0646\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0181 - mse: 0.0331 - val_loss: 0.0321 - val_mse: 0.0632\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0172 - mse: 0.0316 - val_loss: 0.0315 - val_mse: 0.0623\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - mse: 0.0308 - val_loss: 0.0305 - val_mse: 0.0604\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0159 - mse: 0.0296 - val_loss: 0.0296 - val_mse: 0.0589\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0153 - mse: 0.0285 - val_loss: 0.0282 - val_mse: 0.0564\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0144 - mse: 0.0270 - val_loss: 0.0271 - val_mse: 0.0543\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0135 - mse: 0.0254 - val_loss: 0.0264 - val_mse: 0.0532\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0130 - mse: 0.0244 - val_loss: 0.0262 - val_mse: 0.0528\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0127 - mse: 0.0237 - val_loss: 0.0260 - val_mse: 0.0526\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0124 - mse: 0.0231 - val_loss: 0.0258 - val_mse: 0.0523\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0123 - mse: 0.0230 - val_loss: 0.0258 - val_mse: 0.0523\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0119 - mse: 0.0224 - val_loss: 0.0256 - val_mse: 0.0521\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0118 - mse: 0.0221 - val_loss: 0.0257 - val_mse: 0.0521\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0220 - val_loss: 0.0254 - val_mse: 0.0516\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0116 - mse: 0.0216 - val_loss: 0.0254 - val_mse: 0.0516\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0115 - mse: 0.0214 - val_loss: 0.0251 - val_mse: 0.0512\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0113 - mse: 0.0212 - val_loss: 0.0251 - val_mse: 0.0511\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0112 - mse: 0.0210 - val_loss: 0.0249 - val_mse: 0.0505\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0110 - mse: 0.0206 - val_loss: 0.0245 - val_mse: 0.0500\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0109 - mse: 0.0204 - val_loss: 0.0245 - val_mse: 0.0499\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0107 - mse: 0.0201 - val_loss: 0.0242 - val_mse: 0.0492\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0105 - mse: 0.0195 - val_loss: 0.0238 - val_mse: 0.0485\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0103 - mse: 0.0192 - val_loss: 0.0232 - val_mse: 0.0474\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0100 - mse: 0.0185 - val_loss: 0.0227 - val_mse: 0.0463\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0097 - mse: 0.0179 - val_loss: 0.0224 - val_mse: 0.0455\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0095 - mse: 0.0176 - val_loss: 0.0218 - val_mse: 0.0444\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0094 - mse: 0.0172 - val_loss: 0.0214 - val_mse: 0.0437\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0092 - mse: 0.0169 - val_loss: 0.0213 - val_mse: 0.0436\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0090 - mse: 0.0165 - val_loss: 0.0209 - val_mse: 0.0428\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0091 - mse: 0.0167 - val_loss: 0.0206 - val_mse: 0.0423\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0089 - mse: 0.0164 - val_loss: 0.0202 - val_mse: 0.0416\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0087 - mse: 0.0161 - val_loss: 0.0198 - val_mse: 0.0408\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0086 - mse: 0.0160 - val_loss: 0.0197 - val_mse: 0.0406\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0085 - mse: 0.0157 - val_loss: 0.0194 - val_mse: 0.0401\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0085 - mse: 0.0156 - val_loss: 0.0193 - val_mse: 0.0400\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0084 - mse: 0.0156 - val_loss: 0.0190 - val_mse: 0.0395\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0083 - mse: 0.0154 - val_loss: 0.0187 - val_mse: 0.0390\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0082 - mse: 0.0151 - val_loss: 0.0185 - val_mse: 0.0386\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0083 - mse: 0.0152 - val_loss: 0.0184 - val_mse: 0.0384\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0082 - mse: 0.0150 - val_loss: 0.0181 - val_mse: 0.0378\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0081 - mse: 0.0151 - val_loss: 0.0182 - val_mse: 0.0379\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0079 - mse: 0.0146 - val_loss: 0.0178 - val_mse: 0.0372\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0080 - mse: 0.0149 - val_loss: 0.0177 - val_mse: 0.0368\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "autoencoder_5 = Autoencoder(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "autoencoder_5.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_5 = autoencoder_5.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 94,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dq0HmQDVwz1C",
        "outputId": "92ceb2a7-4b2f-4867-e5e9-68fe0c867f2a"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 2ms/step\n",
            "Threshold: 0.01051551705104101\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.86      0.86      0.86       176\n",
            "           1       0.86      0.86      0.86       176\n",
            "\n",
            "    accuracy                           0.86       352\n",
            "   macro avg       0.86      0.86      0.86       352\n",
            "weighted avg       0.86      0.86      0.86       352\n",
            "\n",
            "AUC: 0.8607954545454546\n"
          ]
        }
      ],
      "source": [
        "performance(autoencoder_5, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "DisjYcdo2d2I"
      },
      "source": [
        "# 7. Save and load the best model\n",
        "\n",
        "The best model is `autoencoder_2` with AUC = 88.35"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 97,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LGpCY2ruyF5d",
        "outputId": "a33a4ee9-0907-4a23-b5e8-aa8607bc7005"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Save the entire model as a SavedModel.\n",
        "!mkdir -p saved_model\n",
        "autoencoder_2.save('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 98,
      "metadata": {
        "id": "aai4Hjz212qB"
      },
      "outputs": [],
      "source": [
        "# Reload the saved model\n",
        "new_model = tf.keras.models.load_model('saved_model/my_model')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 99,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "tDnAkrre2p7n",
        "outputId": "c2c68142-cb9f-42bc-cf05-eb4a92e54dd6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "Threshold: 0.016654403516558874\n",
            "11/11 [==============================] - 0s 4ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.82      0.88       176\n",
            "           1       0.84      0.94      0.89       176\n",
            "\n",
            "    accuracy                           0.88       352\n",
            "   macro avg       0.89      0.88      0.88       352\n",
            "weighted avg       0.89      0.88      0.88       352\n",
            "\n",
            "AUC: 0.8835227272727273\n"
          ]
        }
      ],
      "source": [
        "performance(new_model, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "attachments": {},
      "cell_type": "markdown",
      "metadata": {
        "id": "SvtXfegx3ZmA"
      },
      "source": [
        "# 8. Test new architecture of model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 100,
      "metadata": {
        "id": "iuxLduPr2vcA"
      },
      "outputs": [],
      "source": [
        "# Create a model by subclassing Model class in tensorflow\n",
        "class AutoencoderV2(Model):\n",
        "  \"\"\"\n",
        "  An autoencoder with Encoder and decoder blocks\n",
        "  \n",
        "  Arguments:\n",
        "    input_dim -- number of NN units at layer 0 (input)\n",
        "         \n",
        "  Returns: \n",
        "    autoencoder -- autoencoder Model\n",
        "  \"\"\"\n",
        "\n",
        "  def __init__(self, input_dim):\n",
        "    super().__init__()\n",
        "    # encoder block\n",
        "    self.encoder = Sequential([\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(8, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(4, activation='relu')\n",
        "    ])\n",
        "    # Decoder block\n",
        "    self.decoder = Sequential([\n",
        "        Dense(8, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(16, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(32, activation='relu'),\n",
        "        Dropout(0.1),\n",
        "        Dense(input_dim, activation='sigmoid')\n",
        "    ])\n",
        "\n",
        "  def call(self, inputs):\n",
        "    encode = self.encoder(inputs)\n",
        "    decode = self.decoder(encode)\n",
        "    return decode"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 101,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "4Qn0BYVJ3pEr",
        "outputId": "3c9804de-baf9-4aa9-b54b-6a9bc4cbf1de"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/20\n",
            "12/12 [==============================] - 2s 17ms/step - loss: 0.0712 - mse: 0.1169 - val_loss: 0.0785 - val_mse: 0.1330\n",
            "Epoch 2/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0689 - mse: 0.1126 - val_loss: 0.0757 - val_mse: 0.1280\n",
            "Epoch 3/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0647 - mse: 0.1049 - val_loss: 0.0702 - val_mse: 0.1183\n",
            "Epoch 4/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0562 - mse: 0.0898 - val_loss: 0.0594 - val_mse: 0.1006\n",
            "Epoch 5/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0422 - mse: 0.0671 - val_loss: 0.0442 - val_mse: 0.0786\n",
            "Epoch 6/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0294 - mse: 0.0489 - val_loss: 0.0358 - val_mse: 0.0695\n",
            "Epoch 7/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0234 - mse: 0.0407 - val_loss: 0.0326 - val_mse: 0.0641\n",
            "Epoch 8/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0208 - mse: 0.0367 - val_loss: 0.0320 - val_mse: 0.0629\n",
            "Epoch 9/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0194 - mse: 0.0346 - val_loss: 0.0320 - val_mse: 0.0632\n",
            "Epoch 10/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0186 - mse: 0.0335 - val_loss: 0.0320 - val_mse: 0.0633\n",
            "Epoch 11/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0180 - mse: 0.0326 - val_loss: 0.0318 - val_mse: 0.0629\n",
            "Epoch 12/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0175 - mse: 0.0320 - val_loss: 0.0317 - val_mse: 0.0629\n",
            "Epoch 13/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0172 - mse: 0.0315 - val_loss: 0.0315 - val_mse: 0.0625\n",
            "Epoch 14/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0169 - mse: 0.0311 - val_loss: 0.0314 - val_mse: 0.0623\n",
            "Epoch 15/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0305 - val_loss: 0.0312 - val_mse: 0.0620\n",
            "Epoch 16/20\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0162 - mse: 0.0300 - val_loss: 0.0309 - val_mse: 0.0616\n",
            "Epoch 17/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0160 - mse: 0.0297 - val_loss: 0.0307 - val_mse: 0.0613\n",
            "Epoch 18/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0159 - mse: 0.0296 - val_loss: 0.0306 - val_mse: 0.0610\n",
            "Epoch 19/20\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0156 - mse: 0.0291 - val_loss: 0.0302 - val_mse: 0.0604\n",
            "Epoch 20/20\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0288 - val_loss: 0.0299 - val_mse: 0.0600\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "auto_v2 = AutoencoderV2(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "auto_v2.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 20\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_v2 = auto_v2.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 102,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "gD9SRWz638HU",
        "outputId": "d6a73e9c-9b13-43ab-8e33-12f0b3ef9dea"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "Threshold: 0.02151638411884621\n",
            "11/11 [==============================] - 0s 3ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.93      0.80      0.86       176\n",
            "           1       0.82      0.94      0.88       176\n",
            "\n",
            "    accuracy                           0.87       352\n",
            "   macro avg       0.88      0.87      0.87       352\n",
            "weighted avg       0.88      0.87      0.87       352\n",
            "\n",
            "AUC: 0.8693181818181819\n"
          ]
        }
      ],
      "source": [
        "performance(auto_v2, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 103,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "OVlZFJqB4DFQ",
        "outputId": "08150f58-e211-4d06-8700-a895c597b4f6"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Epoch 1/50\n",
            "12/12 [==============================] - 2s 17ms/step - loss: 0.0713 - mse: 0.1172 - val_loss: 0.0785 - val_mse: 0.1329\n",
            "Epoch 2/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0688 - mse: 0.1124 - val_loss: 0.0748 - val_mse: 0.1263\n",
            "Epoch 3/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0633 - mse: 0.1021 - val_loss: 0.0668 - val_mse: 0.1122\n",
            "Epoch 4/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0516 - mse: 0.0821 - val_loss: 0.0520 - val_mse: 0.0888\n",
            "Epoch 5/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0363 - mse: 0.0586 - val_loss: 0.0383 - val_mse: 0.0711\n",
            "Epoch 6/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0270 - mse: 0.0457 - val_loss: 0.0337 - val_mse: 0.0659\n",
            "Epoch 7/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0231 - mse: 0.0403 - val_loss: 0.0324 - val_mse: 0.0636\n",
            "Epoch 8/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0212 - mse: 0.0374 - val_loss: 0.0323 - val_mse: 0.0636\n",
            "Epoch 9/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0201 - mse: 0.0359 - val_loss: 0.0321 - val_mse: 0.0636\n",
            "Epoch 10/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0189 - mse: 0.0342 - val_loss: 0.0320 - val_mse: 0.0629\n",
            "Epoch 11/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0187 - mse: 0.0338 - val_loss: 0.0316 - val_mse: 0.0625\n",
            "Epoch 12/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0179 - mse: 0.0326 - val_loss: 0.0314 - val_mse: 0.0619\n",
            "Epoch 13/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0175 - mse: 0.0319 - val_loss: 0.0311 - val_mse: 0.0614\n",
            "Epoch 14/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0171 - mse: 0.0315 - val_loss: 0.0307 - val_mse: 0.0608\n",
            "Epoch 15/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0167 - mse: 0.0307 - val_loss: 0.0305 - val_mse: 0.0604\n",
            "Epoch 16/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0165 - mse: 0.0304 - val_loss: 0.0304 - val_mse: 0.0603\n",
            "Epoch 17/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0161 - mse: 0.0299 - val_loss: 0.0301 - val_mse: 0.0600\n",
            "Epoch 18/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0159 - mse: 0.0295 - val_loss: 0.0297 - val_mse: 0.0594\n",
            "Epoch 19/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0158 - mse: 0.0294 - val_loss: 0.0295 - val_mse: 0.0589\n",
            "Epoch 20/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0156 - mse: 0.0290 - val_loss: 0.0291 - val_mse: 0.0582\n",
            "Epoch 21/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0154 - mse: 0.0287 - val_loss: 0.0286 - val_mse: 0.0574\n",
            "Epoch 22/50\n",
            "12/12 [==============================] - 0s 8ms/step - loss: 0.0150 - mse: 0.0280 - val_loss: 0.0281 - val_mse: 0.0564\n",
            "Epoch 23/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0146 - mse: 0.0272 - val_loss: 0.0275 - val_mse: 0.0555\n",
            "Epoch 24/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0144 - mse: 0.0270 - val_loss: 0.0274 - val_mse: 0.0551\n",
            "Epoch 25/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0143 - mse: 0.0267 - val_loss: 0.0270 - val_mse: 0.0546\n",
            "Epoch 26/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0138 - mse: 0.0260 - val_loss: 0.0271 - val_mse: 0.0547\n",
            "Epoch 27/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0137 - mse: 0.0257 - val_loss: 0.0269 - val_mse: 0.0544\n",
            "Epoch 28/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0134 - mse: 0.0252 - val_loss: 0.0268 - val_mse: 0.0543\n",
            "Epoch 29/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0133 - mse: 0.0251 - val_loss: 0.0268 - val_mse: 0.0543\n",
            "Epoch 30/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0131 - mse: 0.0247 - val_loss: 0.0267 - val_mse: 0.0540\n",
            "Epoch 31/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0132 - mse: 0.0249 - val_loss: 0.0268 - val_mse: 0.0542\n",
            "Epoch 32/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0128 - mse: 0.0241 - val_loss: 0.0266 - val_mse: 0.0539\n",
            "Epoch 33/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0129 - mse: 0.0243 - val_loss: 0.0265 - val_mse: 0.0537\n",
            "Epoch 34/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 0.0237 - val_loss: 0.0265 - val_mse: 0.0536\n",
            "Epoch 35/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0126 - mse: 0.0237 - val_loss: 0.0264 - val_mse: 0.0535\n",
            "Epoch 36/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0125 - mse: 0.0235 - val_loss: 0.0264 - val_mse: 0.0536\n",
            "Epoch 37/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0124 - mse: 0.0234 - val_loss: 0.0263 - val_mse: 0.0536\n",
            "Epoch 38/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0122 - mse: 0.0231 - val_loss: 0.0265 - val_mse: 0.0537\n",
            "Epoch 39/50\n",
            "12/12 [==============================] - 0s 7ms/step - loss: 0.0122 - mse: 0.0230 - val_loss: 0.0263 - val_mse: 0.0535\n",
            "Epoch 40/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0122 - mse: 0.0230 - val_loss: 0.0262 - val_mse: 0.0534\n",
            "Epoch 41/50\n",
            "12/12 [==============================] - 0s 5ms/step - loss: 0.0120 - mse: 0.0227 - val_loss: 0.0262 - val_mse: 0.0533\n",
            "Epoch 42/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0227 - val_loss: 0.0263 - val_mse: 0.0536\n",
            "Epoch 43/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0120 - mse: 0.0227 - val_loss: 0.0262 - val_mse: 0.0534\n",
            "Epoch 44/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0225 - val_loss: 0.0262 - val_mse: 0.0533\n",
            "Epoch 45/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0119 - mse: 0.0225 - val_loss: 0.0261 - val_mse: 0.0533\n",
            "Epoch 46/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0222 - val_loss: 0.0261 - val_mse: 0.0533\n",
            "Epoch 47/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0223 - val_loss: 0.0260 - val_mse: 0.0532\n",
            "Epoch 48/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0118 - mse: 0.0222 - val_loss: 0.0259 - val_mse: 0.0530\n",
            "Epoch 49/50\n",
            "12/12 [==============================] - 0s 4ms/step - loss: 0.0116 - mse: 0.0220 - val_loss: 0.0258 - val_mse: 0.0527\n",
            "Epoch 50/50\n",
            "12/12 [==============================] - 0s 6ms/step - loss: 0.0117 - mse: 0.0220 - val_loss: 0.0256 - val_mse: 0.0524\n"
          ]
        }
      ],
      "source": [
        "# Create autoencoder model\n",
        "auto_v3 = AutoencoderV2(input_dim=X_train_scaled.shape[1])\n",
        "\n",
        "# Loss and optimizer definition\n",
        "auto_v3.compile(optimizer=tf.keras.optimizers.Adam(),\n",
        "                    loss='msle',  #  Computes the mean squared logarithmic error between y_true & y_pred.\n",
        "                    metrics=['mse']) \n",
        "\n",
        "# Training model\n",
        "EPOCHS = 50\n",
        "BATCH_SIZE = 128\n",
        "\n",
        "# Fit the autoencoder\n",
        "history_v3 = auto_v3.fit(x=X_train_scaled, \n",
        "                          y=X_train_scaled,\n",
        "                          epochs=EPOCHS,\n",
        "                          batch_size=BATCH_SIZE,\n",
        "                          validation_data=(X_test_scaled, X_test_scaled),\n",
        "                          shuffle=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 104,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qoAKK0KD4SNQ",
        "outputId": "9b20b6d1-a938-4105-b50d-c4b6e871832d"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 2ms/step\n",
            "Threshold: 0.016718616889630153\n",
            "11/11 [==============================] - 0s 1ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.89       176\n",
            "           1       0.86      0.95      0.90       176\n",
            "\n",
            "    accuracy                           0.89       352\n",
            "   macro avg       0.90      0.89      0.89       352\n",
            "weighted avg       0.90      0.89      0.89       352\n",
            "\n",
            "AUC: 0.8948863636363635\n"
          ]
        }
      ],
      "source": [
        "performance(auto_v3, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 109,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qxSTG-Mm5YYo",
        "outputId": "6844ec5d-f388-44b3-8a55-19c4460e55d0"
      },
      "outputs": [
        {
          "name": "stderr",
          "output_type": "stream",
          "text": [
            "WARNING:absl:Found untraced functions such as _update_step_xla while saving (showing 1 of 1). These functions will not be directly callable after loading.\n"
          ]
        }
      ],
      "source": [
        "# Save the model auto_v3 with AUC=0.89\n",
        "auto_v3.save('saved_model/auto_v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 118,
      "metadata": {
        "id": "sA92kSSj-INV"
      },
      "outputs": [],
      "source": [
        "# Reload model auto_v3\n",
        "reload_auto_v3 = tf.keras.models.load_model('saved_model/auto_v3')"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 119,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2j9PKdrY-YL5",
        "outputId": "477c518c-1ab0-497a-8fba-ba9c18519176"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "47/47 [==============================] - 0s 1ms/step\n",
            "Threshold: 0.016718616889630153\n",
            "11/11 [==============================] - 0s 2ms/step\n",
            "              precision    recall  f1-score   support\n",
            "\n",
            "           0       0.94      0.84      0.89       176\n",
            "           1       0.86      0.95      0.90       176\n",
            "\n",
            "    accuracy                           0.89       352\n",
            "   macro avg       0.90      0.89      0.89       352\n",
            "weighted avg       0.90      0.89      0.89       352\n",
            "\n",
            "AUC: 0.8948863636363635\n"
          ]
        }
      ],
      "source": [
        "performance(reload_auto_v3, X_train_scaled, X_test_scaled)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4KvZO9xk-c-d"
      },
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.9.0"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
